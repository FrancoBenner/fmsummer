\chapter{Portfolio Optimization, Transaction Costs \& Dynamic Games 1 - Muhle-Karbe}
\begin{enumerate}
	\item Setting
	\item Frictionless Control Heuristics (no transaction costs)
	\item Verification via Convex Duality
	\item Control Heuristics with Transaction Costs
	\item Verification via Shadow Prices
\end{enumerate}

We'll consider the Black-Merton-Scholes model with two assets:
\begin{enumerate}
	\item Safe asset normalized to $S^0_t=1$
	\item Risky asset following geometric Brownian Motion:
	\begin{equation}
		\frac{dS_t}{S_t} = \mu dt + \sigma dW_t
	\end{equation}
	for a standard Brownian motion $(W_t)_{t\geq 0}$ defined on a filtered probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t\geq 0}, P)$.
	\item Returns have constant expectations $\mu > 0$, vol $\sigma >0$
	\item simplest benchmark
	\item no tx costs
\end{enumerate}

We start with a positive cash endowment $x > 0$. An investor c hooses number $\varphi_t$ of risky shares. Corresponding wealth process:
\begin{equation}
	X_t^{\varphi} = x + \int_0^t \varphi_s dS_s
\end{equation}
The safe position implicitly determined by self-financing condition:
\begin{equation}
	\varphi_t^0 = x + \int_0^t \varphi_s dS_s - \varphi_t S_t
\end{equation}
To make everything well-defined, $(\varphi_t)_{t\geq 0}$ needs to be $S$-integrable:
\begin{equation}
	\int_0^t \varphi_s^s ds < \infty \qquad \forall t \geq 0
\end{equation}

Preferences: Investor maximize expected utility from terminal wealth at some time horizon $T>0$:
\begin{equation}
	\mathbb{E}\left[ U(X^\varphi_T) \right] \to \text{max}
\end{equation}
over all trading strategies $\varphi_t$.

The utility function $U$ should:
\begin{enumerate}
	\item be increasing: more is better than less.
	\item Concave: risky payoff is worth than its expectation
	\item Inada conditions: Extra dollar matters a lot when poor, irrelevant when rich. (Codify in math by:
	\begin{align}
		\lim_{x\to \infty} U'(x) \to 0\\
		\lim_{x\to 0} U'(x) \to \infty
	\end{align})
\end{enumerate}

One messiness here is this: The units are goofy. An alternative is to use a different unit.
A better interpretation is: maximize certainty equivalent:
\begin{equation}
	CE(\varphi) = U^{-1}(\mathbb{E}\left[ U(X_T^\varphi) \right]) \to \text{max}
\end{equation}

How can we determine optimal strategy and utility? There's a complex dependence on market parameters, investment horizon, and preferences! How can we tackle an infinite dimensional stochastic control problem? Today, we'll do a heuristic derivation and tomorrow, we'll do a rigorous verification.

We first make the problem harder: via a value function like
\begin{equation}
	v(t,x) := \sup_{(\varphi_s)_{s\in[t,T]}} \mathbb{E}\left[ U(x + \int_t^T \varphi_s dS_s) | \mathcal{F}_t\right]
\end{equation}, which evaluates along any wealth process $X_t^\varphi$ (a supermartingale with nonpositive drift) and along optimal wealth $X_t^{\hat{\varphi}}$(martingale with zero drift.) This boils down to: ``Martingale optimality principle of stochastic control.'' 

What do we mean by all of this? We start with
\begin{align}
	\mathbb{E}& \left[ v(t,X_t^\varphi) | \mathcal{F}_s \right] \\
	 =& \mathbb{E} \left[ \mathbb{E}\left[ U(X^\varphi_t + \int_t^T \hat{\varphi}_s dS_s) | \mathcal{F}_t\right] | \mathcal{F}_s \right] \\
	=& \mathbb{E} \left[ U(X^\varphi_t + \int_t^T \hat{\varphi}_s dS_s) | \mathcal{F}_s \right] \\
	=& \mathbb{E} \left[ U(X^\varphi_s + \int_s^t \hat{\varphi}_s dS_s)+ \int_t^T \hat{\varphi}_s dS_s) | \mathcal{F}_s \right] \\
	\leq& \mathbb{E} \left[ U(X^\varphi_s + \int_s^T \hat{\varphi}_s dS_s) | \mathcal{F}_s \right] \\
	=& v(s,x_s^\varphi)
\end{align}

How can we use the martingale optimality princeiple? The value function $v(t,x)$ generally can depend on many state variables. Here, the wealth dynamics
\begin{align}
	d X_t^\varphi = \mu \varphi_t S_t dt + \sigma \varphi_t S_t dW_t\\
			=& \mu \eta_t dt + \sigma \eta_t dW_t
\end{align}
for some risky position $\eta_t$ only depend on the control $\eta_t$. One guess is a value function only depends on the initial wealth $x$ and time $t$. This is an assumption!! Not a result. This needs to be verified eventually.

Suppose that the value function is smooth. Then Ito's formula yields
\begin{equation}
	dv(t, X^\eta_t) = (v_t + \mu \eta_t v_x + \frac{\sigma^2}{2}\eta^2_t v_{xx})dt + (...) dW_t
\end{equation}
This should be a supermartingale for any $\eta_t$: drift $\leq 0$. It will also be a martingale for the optimizer $\hat{\eta}_t$: with drift = 0. Then maximize drift pointwise in $\eta_t$. Plug in maximizer. Set to zero. This yields equations for optimal stategry and value functions.

% missed some stuff here...

We can consider a special case: Take the exponential utility function $U(x) = -e^{-ax}$, and factor the wealth out via $v(t,x) = e^{-ax}v(t,0)$, with the constant absolute risk-tolerance $1/a$. This gives the constant risky position
\begin{equation}
	\hat{\eta}_t = \frac{\mu}{a \sigma^2}
\end{equation}
This is independent of horizon. It is independent of wealth. The value function and certainty-equivalent are the same.
\begin{equation}
	v(t,x) = -e^{-ax} \exp(\frac{\mu^2}{2\sigma^2(t-T)}) \implies CE(\hat{\varphi}) = x + \frac{\mu^2}{2 a \sigma^2} T
\end{equation}
Here, the assets are ranked by the Sharpe ratio $\mu/\sigma$. The same Sharpe ratio leads to the same payoffs.


An alternative: If we have twice as much money, we are willing to take twice as much risk. This is debatable, but why not??

\begin{equation}
	U(x) = \frac{x^{1-\gamma}}{1-\gamma} 
\end{equation}
rederive v(t,x), risk tolerance, proportion, value function, certainty equivalent.
\begin{equation}
	v(t,x) = x^{1-\gamma} v(t,1)
\end{equation}
Constant relative risk-tolerance $x/\gamma$.
Constant risky proportion $\hat{\pi}_t := \hat{\eta}_t / X^{\hat{\eta}}_{t} = \mu / \gamma \sigma^2$, which is independent of horizon.
Investment scales with wealth.

Value function and certainty equivalent:

\chapter{Lecture 2}
We can verify that all of this actually works.

\section{Verification via Convex Duality}
Need to rule out doubling strategies.
Usual notion: $X^\varphi_t \geq -C$ (we have a bounded credit line).
The value $C=0$ works well for utilities defined on $\mathbb{R}_+$; optimal wealth process for power utility follows geometric Brownian motion:
\begin{equation}
	\frac{dX_t^{\hat{\pi}}}{X_t^{\hat{\pi}}} = \frac{\mu}{\gamma \sigma^2} (\mu dt + \sigma dW_t)
\end{equation}
This is not compatible with utilities on $\mathbb{R}$: optimal wealth processes for exponential utility follows brownian motion with drift:
\begin{equation}
	dX_t^{\hat{\eta}} = \frac{\mu}{\alpha \sigma^2} (\mu dt + \sigma dW_t)
\end{equation}

How can we verify?

\subsection{Convex Duality}
For a concave function $U$, we can define the conjugate:
\begin{equation}
	V(y) = \sup_{x > 0} \{ U(x) - xy \}
\end{equation}
Then
\begin{equation}
	\mathbb{E}\left[ U(X^\varphi_T) \right] \leq 
	\mathbb{E}\left[ V(yY_T) \right] + \mathbb{E}\left[ X_TY_T \right]
	= \mathbb{E}\left[ V(yY_T) \right] + \mathbb{E}_Q\left[ X_T^\varphi \right]y
\end{equation}
for $y>0$ and density process $Y_t$ of an EMM $\mathbb{Q}$.

Then $X_t^\varphi = x + \int_0^t \varphi_s dS_s$ is a local Q-martingale.
\begin{enumerate}
	\item Supermartingale if bounded from below for utilities on $\mathbb{R}_+$
	\item Martingale if risky position is sufficiently integrable for utilities on $\mathbb{R}$ (eg, bounded). This implies admissibility.
\end{enumerate}

In either case, $\mathbb{E}[U(X_T^\varphi)] \leq \mathbb{E}[V(yY_T)] + xy$.

This upper bound is for any trading strategy $\varphi$, any $t$, and any $y$. Candidate is optimal if bound is tight for
\begin{enumerate}
	\item $U'(X_t^\varphi) = yY_t$
	\item $\mathbb{E}[ Y_T (U')^{-1}(yY_T) ] = x$
\end{enumerate}

For exponential utilities $U(x) = -e^{-\alpha x}$, we get $V(y) = \frac{y}{\alpha} \log \frac{y}{\alpha} - 1$. The second condition gives $y = \alpha \exp (-\alpha x - \mathbb{E}[ Y_T \log Y_T ])$. This yields a simplified upper bound:
\begin{equation}
	\mathbb{E} [ -e^{-\alpha X_T^\varphi}] \leq -e^{-\alpha x - \mathbb{E} [ Y_t \log Y_T ]}
\end{equation}

In complete market with unique $Y_T$, we can verify equality for candidate by direct computation! Sweet!


We can do analogous results for power utilities $U(x) = x^{1-\gamma}/ (1-\gamma)$. The conjugate comes out to $V(y) = \frac{\gamma}{1-\gamma} y^{1-1/\gamma}$. Then we look at the expectation, and look at the upper duality bound simplifies.


\section{Markets with Transaction Costs}
Before, we bought and sold at the same price $S_t$. Now, we will buy at the ask price $S_t$ and sell at the bid price $(1-\epsilon)S_t$. (clearly, $\epsilon$ is the width of the relative bid-ask spread.)  We only consider finite variation strategies $\varphi_t = \varphi_t^u - \varphi_t^d$. These track the number of shares bought and sold by time $t$, respectively. Infinite costs otherwise.

We can do integration by parts on the frictionless self-financing condition, which then reads as
\begin{equation}
	d\varphi_t^0 = \varphi_t dS_t - d(\varphi_tS_t) = -S_td\varphi_t
\end{equation}
The counterpart with transaction costs is
\begin{equation}
	d\varphi_t^0  = -S_td\varphi_t^u + (1-\epsilon)S_t d\varphi_t^d.
\end{equation}

Why is all of this important? Non-trivial spreads are common even in the most liquid markets. Constant position/weight requires infinite turnover, which causes infinite costs, which is not feasible. How can we adapt optimal trading strategies? How much welfare is lost? What are the endogenous spreads in equilibrium between market makers and rebalancing investors? (This is a sort of static game which can determine the bid-ask spread as an output of a model such as: Find a bid-ask spread by examining market maker profit from optimal strategy of traders given a bid-ask spread.) There is also a new difficulty: complex horizon dependence. Do not trade if horizon is close. Way out?

Two alternatives:
\begin{enumerate}
	\item We could look at the expected utility of the final value of our portfolio:
	\begin{equation}
		\mathbb{E}[U(X_T)]
	\end{equation}
	but this is a bit fishy...
	
	\item Another option is to look at
	\begin{equation}
		\mathbb{E}[ \int_0^\infty e^{-\beta t} U(c_t)dt ] 
	\end{equation}
	which is good, except that it is basically intractable.
\end{enumerate}

So, as before, we'll consider the exponential utility $U(x) = -e^{-\alpha x}$ or power utility $U(x) = \frac{x^{1-\gamma}}{1-\gamma}$. 
But infinite horion to reduce stationary problem:
	For exponential utilities, we maximize the equivalent annuity:
	\begin{equation}
		\limsup_{T\to \infty} - \frac{1}{\alpha T} \log \mathbb{E}\left[e^{-\alpha X_T^\varphi} \right] \to \max!
	\end{equation}
	
	For power utilities, we maximize the equivalent safe rate:
	\begin{equation}
		\limsup_{T\to \infty} \frac{1}{(1-\gamma) T} \log \mathbb{E}\left[ (X^\varphi_T)^{1-\gamma} \right] \to \max!
	\end{equation}

This keeps scaling properties in the wealth, and also gets rid of the horizon dependence.

Open questions: What are the control heuristics? How can we verify it?

% \chapter{lecture 3}
% \chapter
\chapter{Lecture 5}
[tcj: Missing lectures 3/4 because notes online.]

Idea: Directly tackle asymptotic optimality equations.

General model: General asset prices, costs, preferences. Normalize the safe asset to one. The risky asset will be traded with proportional costs $\epsilon_t=\epsilon {\bf\epsilon}_t>0$. The mid price will be given by
\begin{equation}
	dS_t = b_t^S dt + \sqrt{c_t^S} dW_t
\end{equation}
This gives the general diffusive dynamics. We can include heteroskedasticity and predictable returns leading to market timing. We do not need any markovian structure.

Why doe we need general asset prices? Transaction costs have small effect in Black-Scholes model, because investors essentially should buy and hold, and then profit from the market growth.

On the other hand, Mnay strategies are market neutral. They make a profit by active trading. For example: Buy low, sell high for a mean-reverting instrument, which might be governed by
\begin{equation}
	dS_t = -\lambda S_t dt + dW_t
\end{equation}
or a momentum strategy, which says: go long in good times, short in bad times. That gives:
\begin{align}
	dS_t =& \mu_t dt + \sigma dW_t,\\
	d\mu_t =& -\lambda \mu_t dt + \sigma_\mu dW_t^\mu
\end{align}
In these cases, it is much harder to avoid the transaction costs. We will need to find a direct tradeoff between the gains from trading and costs incurred by trading.

Here, the investor will solve
\begin{equation}
	\mathbb{E} \left[ \int_0^T U_1(t,\kappa_t^{\epsilon})dt + U_2(X_T^\epsilon(\varphi^\epsilon, \kappa^\epsilon))\right] \to \max
\end{equation}
over all policies $(\varphi_t^\epsilon, \kappa^\epsilon_t)$.


Motivations:
\begin{enumerate}
	\item Individual household: Receive labour income stream, consumes over lfetime
	\item Retirement Fund: Maximize long-run expected utility from terminal wealth
	\item Option trading board: Hedge derivative until maturity.
	\item Hedge Fund: time the market on short horizon.
\end{enumerate}
Here, the general model incorporates all these asset prices and optimization problems.

The optimal policy is to consume at the rate: $\kappa_t^\epsilon = \kappa_t + \kappa_t'(X_t^\epsilon - X_t)$. We will trade to keep the risky shares $\varphi^\epsilon$ in some no-trade region $\left[\overline{NT}_t - \Delta NT_t, \overline{NT}_t + \Delta NT_t \right]$. Clearly, the midpoint is given 
\begin{equation}
	\overline{NT}^\epsilon = \varphi_t + \varphi_t'(X_t^\epsilon - X_t)
\end{equation}

We can determine the halfwidth to be
\begin{equation}
	\Delta NT_t = \pm \left(\frac{3R_t}{2} \frac{d \langle \varphi \rangle_t}{d\langle S \rangle_t}\epsilon_t \right)^{\frac{1}{3}}
\end{equation}
This is determined by a type of portfolio gamma $\frac{d \langle \varphi \rangle_t}{d\langle S \rangle_t}$. This implies that Active strategies require a wide buffer and turbulent markets call for closer tracking.

Note that only the current spread $\epsilon_t$ matters here; future dynamics are hedged at higher orders, but not considered here.

We can do the following calculation: Given $\varphi_t = \Delta(S_t)$, then we have
\begin{equation}
	d\varphi_T = \Delta'(S_t)dS_t + (...) dt
\end{equation}
and then we can consider the quadratic variation which is
\begin{equation}
	\frac{d \langle \varphi_T \rangle_t }{d \langle S \rangle} = (\Delta '(S_t))^2 = \Gamma^2(S_t)
\end{equation}


\chapter{Portfolio Optimization, Transaction Costs, Dynamic Games 6 \\ Sircar}
\section{Announcements}
We'll hold extra discussion sessions as follows:
\begin{enumerate}
	\item Tuesday 13:30: Schied
	\item Wednesday 13:30: Swindle
	\item Thursday 13:30: Cont
	\item Thursday 15:00: Sircar
\end{enumerate}

\section{Dynamic Oligopoly Games}
\subsection{Motivation}
\begin{enumerate}
	\item Try to understand the evolution of energy markets
	\item Competition between different fuels -- a many dimensional problem.
\end{enumerate}
Concerns: Exhaustibility of fossil fuels(Oil running out); Green Energy (renewables, eg Solar); Exploration and Improved technology; 

One approach is to consider the Liquid Financial Markets with a large number of small price takers. The completely opposite extreme is having a small number of relatively large players, all of whom are competing with eachother, and which strongly influence prices. Later in the week we'll return to the financialization of commodities markets.

\section{Cournot Market (1838)}
This is the first example of a Nash equilibrium.
Consider a static, 1 period, two player game.
Key points: This model was set up in the context of producers of mineral water, which is an essentially inexhaustible resource. We can choose quantities $q_1$ and $q_2$ to bring to market. The market is governed by pricing (inverse demand) function $P$: quantity $\mapsto$ price, with $q_1+q_2=Q$. First characteristic: This is a decreasing function! (Flooding the market sents price to zero.) We'll also assume that the goods are perfect substitutes, but that the players have different marginal (ie, per bottle) costs of production $0\leq a_1, a_2 \leq 1$. 

Later, we'll consider these $a_i$ to be dynamic (ie, shadow costs or scarcity costs). For energy, we note that oil is cheap but wind is more expensive.

To set up the competition, we have
\begin{enumerate}
	\item Player 1 objective:
	\begin{equation}
		\max_{q_1\geq 0} q_1 (1-q_1 - q_2 - a_1) 
	\end{equation} 
	\item Player 2 objective:
	\begin{equation}
		\max_{q_2\geq 0} q_2 (1-q_1 - q_2 - a_2) 
	\end{equation}
\end{enumerate}
We can recast these profits as $\Pi_i(q_1,q_2)$. We can solve in the sense of a Nash equilibrium (NE) which is the intersection of the best response:
\begin{align}
	R_1(q_2) =& \arg\max_{q_1} \Pi_1(q_1,q_2)\\
	R_2(q_2) =& \arg\max_{q_2} \Pi_2(q_1,q_2)
\end{align}

A plot of this in the $q_2$ vs $q_1$ shows two triangles, where the hypotenuses intersect is the nash equilibrium.

\begin{definition}\label{def:nash_equil}
	A point $(q_1^*, q_2^*) \in \left[ \right]^2$ is a nash equilibrium if
	\begin{align}
		\Pi_1(q^*_1, q^*_2) \geq \Pi_1(q_1, q_2^*) \forall q_1\\
		\Pi_2(q^*_1, q^*_2) \geq \Pi_2(q_1, q_2^*) \forall q_2
	\end{align}
\end{definition}
We can verify this by noting that
\begin{align}
	R_1(q_2) = \frac12 (1-q_2-a_1)\\
	R_2(q_1) = \frac12 (1-q_1-a_2)
\end{align}
which implies that
\begin{align}
	q_1^* =& \frac{1}{3} (1-2a_1 + a_2) \\
	q_2^* =& \frac{1}{3} (1-2a_1 + a_1) 
\end{align}

Observe that this is decreasing in your costs and increasing in your opponent's cost.

We can calculate an aggregate quantity $Q^*=q_1^* + q_2^2) = \frac13 (2-a_1-a_2)$. We can calculate the market price $P(Q^*) = 1-Q^*=\frac13 (1+a_1 + a_2)$.

We can compare this versus the monopoly case, where the only player will solve
\begin{equation}
	\max_{q\geq 0} q(1-q-a)
	\implies
	q^* = \frac12 (1-a)
\end{equation}
which implies the monopoly price $P_M^* = \frac12(1+a)$.

We can also calculate the duopoly case (ie, where $N=2$) and $a_1=a_2=a$. Then we get $P_D = \frac13 (1+2a) < P_M =\frac12 (1+a)$. Key point: Competition decreases price, which benefits the consumer.

\section{Bertrand (1883) Competition}
Now, consider where firms set prices, not quantities.

\section{Exhaustible Resource Problem}
Hotelling (1931) did this in the monopoly case, while Dasgupta + Heal (1979).

First: Start with two oil producers with finite resources $(x(t), y(t))$. In the Cournot setting, choose the quantities $(q_1(t), q_2(t))$ with
\begin{align}
	\frac{dx}{dt} = -q_1(t) \pi_{\{ x > 0 \} } + (\text{Noise..})\\
	\frac{dy}{dt} = -q_2(t) \pi_{\{ y > 0 \} } + (\text{Noise..})
\end{align}
Now, player 1 will want to solve something like
\begin{equation}
	v(x,y) = \max_{q_1} \int_0^\infty e^{-rt} q_1(t) (1-q_1(t) - q_2(t))dt 
\end{equation}
(this assumes zero cost of production), while player two considers
\begin{equation}
	w(x,y) = \max_{q_2} \int_0^\infty e^{-rt} q_2(t) (1-q_1(t) - q_2(t))dt 
\end{equation}
where $x(0)=x$ and $y(0)=y$.

\section{Dynamic Programming}
We can take the two points with two value functions, and non-zero sum differential games.

\subsection{Recipe}
Introduce
\begin{equation}
	\mathcal{L} = -q_1 \frac{\partial}{\partial x} - q_2\frac{\partial}{\partial y}
\end{equation}
Then
\begin{equation}
	rv = \max_{q_1} \mathcal{L}v + q_1(1-q_1-q_2)
\end{equation}
and similarly,
\begin{equation}
	rw = \max_{q_2} \mathcal{L}w + q_2(1-q_1-q_2)
\end{equation}

Taking this a step ahead, we have
\begin{equation}
	rv = \max_{q_1} \left[ q_1(1-q_1-q_2-\frac{\partial v}{\partial x})\right]  - q_2 \frac{\parital v}{\partial y}
\end{equation}
and 
\begin{equation}
	rw = \max_{q_2} \left[ q_2(1-q_1-q_2-\frac{\partial w}{\partial y})\right]  - q_1 \frac{\parital w}{\partial x}
\end{equation}

If we return to the static two player, and recall the optimal quantity 
\begin{equation}
	q_1^* = \frac13 (1-2a_1+a_2)
\end{equation}
and profit $\Pi_1(a_1,a_2) = q_1^*(1-q_1^*-q_2^*-a_1) = (a_1^*)2$.
Then the PDE that we want to deal with is $y$ vs $x$, on the domain $x\geq 0$, $y\geq 0$, and we want to satisfy the equations
\begin{align}
	\Pi_1(v_x, w_y) - q_2^*(v_x, w_y) \frac{\partial v}{\partial y} = rv\\
	\Pi_2(v_x, w_y) - q_1^*(v_x, w_y) \frac{\partial w}{\partial x} = rw
\end{align}

In the case of inexhaustible oil, then $v=w=$constant. In fact,
\begin{equation}
	v=w=\frac{1}{r} \Pi_{1,2}^*(0,0)
\end{equation}
We can interpret $v_x$ and $w_y$ are shadow costs or scarsity.

Next time: We'll try to model what happens on $x=0$ and $y=0$. (ie, what happens on the exhaustible case?) Either the other player gets a monopoly or we must bring in renewables.









